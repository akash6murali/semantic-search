{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_counterfactual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In person it looks as though it would have cos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product received as described in the shipping ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The handkerchiefs were just what I wanted - so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I adore Nessa and give her  credit because the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He was very pleased when he saw how neat the c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  is_counterfactual\n",
       "0  In person it looks as though it would have cos...                  1\n",
       "1  Product received as described in the shipping ...                  0\n",
       "2  The handkerchiefs were just what I wanted - so...                  0\n",
       "3  I adore Nessa and give her  credit because the...                  0\n",
       "4  He was very pleased when he saw how neat the c...                  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import package and read the data\n",
    "import pandas as pd\n",
    "data =pd.read_csv(\"path/to/amazon-multilingual-counterfactual-dataset/data/EN_train.tsv\", sep=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               sentence  is_counterfactual\n",
      "0     In person it looks as though it would have cos...                  1\n",
      "11              2) I wish the pillow was much fluffier.                  1\n",
      "13    I thought it should have used more of esp or v...                  1\n",
      "15    IF you're buying these CD sleeves PRIMARILY FO...                  1\n",
      "16    They are much bigger than I thought they would...                  1\n",
      "...                                                 ...                ...\n",
      "4004  The padding is a little bulky, but if you want...                  1\n",
      "4005  With I could have found the model without the ...                  1\n",
      "4006  I wish they had one additional option of a mut...                  1\n",
      "4008  Wish i would have returned it while I still co...                  1\n",
      "4017  I must have looked at the reviews and the plot...                  1\n",
      "\n",
      "[765 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[data[\"is_counterfactual\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bge tokenizer to tokenize the statements\n",
    "# max token length is 512 for this model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-base-en-v1.5\")\n",
    "inputs = tokenizer(list(data['sentence']), return_tensors=\"pt\", max_length=512, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pretrained bge model from hugging face\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All embeddings dimensions: torch.Size([4018, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "ds = TensorDataset(inputs['input_ids'], inputs['token_type_ids'], inputs['attention_mask'])\n",
    "data_loader = DataLoader(ds, batch_size=128, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "output_embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        batch_input_ids, batch_token_type_ids, batch_attention_mask = batch\n",
    "        outputs = model(input_ids=batch_input_ids, token_type_ids=batch_token_type_ids, attention_mask=batch_attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        # Extract the CLS token embedding\n",
    "        sentence_embeddings = last_hidden_state[:, 0, :]\n",
    "        output_embeddings.append(sentence_embeddings)\n",
    "\n",
    "# Concatenate all into one array\n",
    "all_embeddings = torch.cat(output_embeddings, dim=0)\n",
    "print(f\"All embeddings dimensions: {all_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 137, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using chromadb as vector database to store the embeddings and efficiently querying similar items\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"counterfactual_collection\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "for i, (documents, embeddings, label) in enumerate(zip(list(data['sentence']), all_embeddings.tolist(), list(data['is_counterfactual']))):\n",
    "    collection.upsert(ids=[str(i)], documents=documents, embeddings=embeddings, metadatas=[{\"is_counterfactual\": label}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counterfactual probability is 10.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"Just who do you think you are talking to right now?\"\n",
    "query_inputs = tokenizer(query, return_tensors=\"pt\", max_length=512, padding=True, truncation=True)\n",
    "query_output = model(input_ids=query_inputs[\"input_ids\"], token_type_ids=query_inputs[\"token_type_ids\"], attention_mask=query_inputs[\"attention_mask\"])\n",
    "# Extract the CLS token embedding\n",
    "query_embeddings = query_output[\"last_hidden_state\"][:, 0, :]\n",
    "query_embeddings_list = query_embeddings.squeeze().tolist()\n",
    "results = collection.query([query_embeddings_list], n_results=10)\n",
    "#results = collection.query(query_embeddings, n_results=10)\n",
    "counterfactual_prob = sum([r[\"is_counterfactual\"] for r in results[\"metadatas\"][0]]) / len(results[\"metadatas\"][0])\n",
    "print(f\"counterfactual probability is {counterfactual_prob * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "F1 Score: 0.62\n",
      "Precision: 0.74\n",
      "Recall: 0.53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "test_data = pd.read_csv(\"path/to/amazon-multilingual-counterfactual-dataset/data/EN_test.tsv\", sep=\"\\t\")\n",
    "cutoff_threshold = 0.5\n",
    "\n",
    "def get_counterfactual_prob(sentence):\n",
    "    query_inputs = tokenizer(sentence, return_tensors=\"pt\", max_length=512, padding=True, truncation=True)\n",
    "    query_output = model(input_ids=query_inputs[\"input_ids\"], token_type_ids=query_inputs[\"token_type_ids\"], attention_mask=query_inputs[\"attention_mask\"])\n",
    "    # Extract the CLS token embedding\n",
    "    query_embeddings = query_output[\"last_hidden_state\"][:, 0, :]\n",
    "    query_embeddings_list = query_embeddings.squeeze().tolist()\n",
    "    results = collection.query([query_embeddings_list], n_results=10)\n",
    "    counterfactual_prob = sum([r[\"is_counterfactual\"] for r in results[\"metadatas\"][0]]) / len(results[\"metadatas\"][0])\n",
    "    return counterfactual_prob\n",
    "\n",
    "predictions = []\n",
    "for index, row in test_data.iterrows():\n",
    "    counterfactual_prob = get_counterfactual_prob(row['sentence'])\n",
    "    prediction = 1 if counterfactual_prob > cutoff_threshold else 0\n",
    "    predictions.append(prediction)\n",
    "\n",
    "accuracy = accuracy_score(test_data['is_counterfactual'], predictions)\n",
    "f1 = f1_score(test_data['is_counterfactual'], predictions)\n",
    "precision = precision_score(test_data['is_counterfactual'], predictions)\n",
    "recall = recall_score(test_data['is_counterfactual'], predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
